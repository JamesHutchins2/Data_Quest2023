{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deriving new Features From Given Data</h1>\n",
    "<p>Using the given data we will try and derive some new feature columns that may yield a better result in the prediction of customer cancellations.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the Train_df\n",
    "Train_df = pd.read_csv('Train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LeadTime</th>\n",
       "      <th>ArrivalYear</th>\n",
       "      <th>ArrivalMonth</th>\n",
       "      <th>ArrivalDate</th>\n",
       "      <th>NumWeekendNights</th>\n",
       "      <th>NumWeekNights</th>\n",
       "      <th>Parking</th>\n",
       "      <th>NumAdults</th>\n",
       "      <th>NumChildren</th>\n",
       "      <th>RepeatedGuest</th>\n",
       "      <th>...</th>\n",
       "      <th>RoomType_Room_Type 7</th>\n",
       "      <th>MealPlan_Meal Plan 1</th>\n",
       "      <th>MealPlan_Meal Plan 2</th>\n",
       "      <th>MealPlan_Meal Plan 3</th>\n",
       "      <th>MealPlan_Not Selected</th>\n",
       "      <th>MarketSegment_Aviation</th>\n",
       "      <th>MarketSegment_Complementary</th>\n",
       "      <th>MarketSegment_Corporate</th>\n",
       "      <th>MarketSegment_Offline</th>\n",
       "      <th>MarketSegment_Online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LeadTime  ArrivalYear  ArrivalMonth  ArrivalDate  NumWeekendNights  \\\n",
       "0        10         2018             3           31                 0   \n",
       "1       116         2018             2           28                 2   \n",
       "2        11         2018             7           25                 1   \n",
       "3         3         2017             9           12                 0   \n",
       "4        28         2018             3            7                 1   \n",
       "\n",
       "   NumWeekNights  Parking  NumAdults  NumChildren  RepeatedGuest  ...  \\\n",
       "0              1        0          1            0              0  ...   \n",
       "1              1        0          1            0              0  ...   \n",
       "2              2        0          2            1              0  ...   \n",
       "3              1        0          2            0              0  ...   \n",
       "4              3        0          2            0              0  ...   \n",
       "\n",
       "   RoomType_Room_Type 7  MealPlan_Meal Plan 1  MealPlan_Meal Plan 2  \\\n",
       "0                     0                     1                     0   \n",
       "1                     0                     1                     0   \n",
       "2                     0                     1                     0   \n",
       "3                     0                     1                     0   \n",
       "4                     0                     1                     0   \n",
       "\n",
       "   MealPlan_Meal Plan 3  MealPlan_Not Selected  MarketSegment_Aviation  \\\n",
       "0                     0                      0                       0   \n",
       "1                     0                      0                       0   \n",
       "2                     0                      0                       0   \n",
       "3                     0                      0                       0   \n",
       "4                     0                      0                       0   \n",
       "\n",
       "   MarketSegment_Complementary  MarketSegment_Corporate  \\\n",
       "0                            0                        1   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   MarketSegment_Offline  MarketSegment_Online  \n",
       "0                      0                     0  \n",
       "1                      0                     1  \n",
       "2                      0                     1  \n",
       "3                      0                     1  \n",
       "4                      1                     0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's create 2 new feature columns</p>\n",
    "<ul>\n",
    "<li>Total customers</li>\n",
    "<li>Total nights to stay</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total customers is children + adults\n",
    "Train_df['Total_Customers'] = Train_df['NumChildren'] + Train_df['NumAdults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total nights\n",
    "Train_df['Total_Nights'] = Train_df['NumWeekNights'] + Train_df['NumWeekendNights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now try running linear regression on the data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the test data and preprocess it\n",
    "Test_df = pd.read_csv('test_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre process the test data\n",
    "Test_df['Total_Customers'] = Test_df['NumChildren'] + Test_df['NumAdults']\n",
    "Test_df['Total_Nights'] = Test_df['NumWeekNights'] + Test_df['NumWeekendNights']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's split the train data into train and test\n",
    "X = Train_df.drop(['isCanceled'], axis=1)\n",
    "y = Train_df['isCanceled']\n",
    "\n",
    "\n",
    "#split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8053066850447967"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preform linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#predict the test data\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "import numpy as np\n",
    "y_pred_round = np.round(y_pred)\n",
    "#compare y_pred_round to y_test\n",
    "\n",
    "#calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's try logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\James\\Desktop\\Data_Quest\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7629221226740179"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can use the same train and test data as before\n",
    "#preform logistic regression\n",
    "lr = LogisticRegression(max_iter=10)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#predict the test data\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "#calculate accuracy\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7567195037904894"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try a svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#we can use the same train and test data as before\n",
    "#preform logistic regression\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "#predict the test data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "#calculate accuracy\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90144727773949"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#we can use the same train and test data as before\n",
    "#preform logistic regression\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#predict the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#calculate accuracy\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8871467953135769"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try tuning the random forest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                            cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#predict the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "#calculate accuracy\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 2.1150 - accuracy: 0.7006 - val_loss: 0.5945 - val_accuracy: 0.7119\n",
      "Epoch 2/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.5767 - accuracy: 0.7344 - val_loss: 0.5516 - val_accuracy: 0.7533\n",
      "Epoch 3/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.5805 - accuracy: 0.7347 - val_loss: 0.4320 - val_accuracy: 0.7998\n",
      "Epoch 4/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.6153 - accuracy: 0.7423 - val_loss: 0.4390 - val_accuracy: 0.7957\n",
      "Epoch 5/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.5556 - accuracy: 0.7510 - val_loss: 0.4454 - val_accuracy: 0.7950\n",
      "Epoch 6/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7517 - val_loss: 0.4191 - val_accuracy: 0.8084\n",
      "Epoch 7/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.5793 - accuracy: 0.7499 - val_loss: 0.6265 - val_accuracy: 0.7331\n",
      "Epoch 8/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.5773 - accuracy: 0.7539 - val_loss: 0.4286 - val_accuracy: 0.8050\n",
      "Epoch 9/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 0.5475 - accuracy: 0.7596 - val_loss: 0.5734 - val_accuracy: 0.7565\n",
      "Epoch 10/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.7549 - val_loss: 0.4871 - val_accuracy: 0.7910\n",
      "182/182 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7910062026188835"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#why not try an RNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#we can use the same train and test data as before\n",
    "#preform logistic regression\n",
    "rnn = Sequential()\n",
    "rnn.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "rnn.add(Dense(32, activation='relu'))\n",
    "rnn.add(Dense(1, activation='sigmoid'))\n",
    "rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#predict the test data\n",
    "y_pred = rnn.predict(X_test)\n",
    "\n",
    "#calculate accuracy using a threshold of 0.5\n",
    "y_pred_round = np.round(y_pred)\n",
    "accuracy_score(y_test, y_pred_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create a function that varies epochs, batch_size, and optimizer, and layers\n",
    "def create_model(epochs, batch_size, optimizer, layers):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115093039283253"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try n nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#we can use the same train and test data as before\n",
    "#preform logistic regression\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#predict the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#calculate accuracy\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "726/726 [==============================] - 3s 2ms/step - loss: 9.1569 - accuracy: 0.4003 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 2/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.1875 - accuracy: 0.3983 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 3/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.2883 - accuracy: 0.3917 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 4/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.2301 - accuracy: 0.3955 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 5/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 9.2512 - accuracy: 0.3941 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 6/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.1821 - accuracy: 0.3986 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 7/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.1850 - accuracy: 0.3984 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 8/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.2174 - accuracy: 0.3963 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 9/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 9.2470 - accuracy: 0.3944 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 10/10\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 9.1468 - accuracy: 0.4009 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "182/182 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32598208132322537"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try a CNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#we can use the same train and test data as before\n",
    "#preform logistic regression\n",
    "cnn = Sequential()\n",
    "cnn.add(Dense(8, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "cnn.add(Dense(8, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "cnn.add(Dropout(0.2))\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#predict the test data\n",
    "y_pred = cnn.predict(X_test)\n",
    "\n",
    "#calculate accuracy using a threshold of 0.5\n",
    "y_pred_round = np.round(y_pred)\n",
    "accuracy_score(y_test, y_pred_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "726/726 [==============================] - 3s 2ms/step - loss: 9.1727 - accuracy: 0.3993 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 2/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.2266 - accuracy: 0.3957 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 3/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.2260 - accuracy: 0.3958 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 4/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.2748 - accuracy: 0.3926 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 5/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.1548 - accuracy: 0.4004 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 6/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.1244 - accuracy: 0.4024 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 7/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.2284 - accuracy: 0.3956 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 8/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.1995 - accuracy: 0.3975 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 9/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.1593 - accuracy: 0.4001 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "Epoch 10/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 9.1575 - accuracy: 0.4002 - val_loss: 10.2783 - val_accuracy: 0.3260\n",
      "182/182 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32598208132322537"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how about an ltsm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#we can use the same train and test data as before\n",
    "#preform logistic regression\n",
    "ltsm = Sequential()\n",
    "ltsm.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "ltsm.add(Dense(32, activation='relu'))\n",
    "ltsm.add(Dense(1, activation='sigmoid'))\n",
    "#add dropout\n",
    "ltsm.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "ltsm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ltsm.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#predict the test data\n",
    "y_pred = ltsm.predict(X_test)\n",
    "\n",
    "#calculate accuracy using a threshold of 0.5\n",
    "y_pred_round = np.round(y_pred)\n",
    "accuracy_score(y_test, y_pred_round)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hyper Parameter Tuning on Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by defining a parameter grid\n",
    "param_grid = {'bootstrap': [True],\n",
    "'max_features': [2, 3,6],\n",
    "'max_depth': [30,120, 100,160, None],\n",
    "'min_samples_leaf': [3, 4, 5,8],\n",
    "'n_estimators': [250,450,550,750]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n",
      "0.8339854667411962\n",
      "0.7885835095137421\n",
      "0.8849347568208779\n"
     ]
    }
   ],
   "source": [
    "#lets run a grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                            cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#predict the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "#calculate accuracy using a threshold of 0.6\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "accuracy_score(y_test, y_pred_round)\n",
    "#get f score, recall    and precision\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "print(f1_score(y_test, y_pred_round))\n",
    "print(recall_score(y_test, y_pred_round))\n",
    "print(precision_score(y_test, y_pred_round))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grid_search_firstNight.pkl']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "#save the model\n",
    "joblib.dump(grid_search, 'grid_search_firstNight.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by defining a parameter grid\n",
    "param_grid = {'bootstrap': [True],\n",
    "'max_features': [1,8],\n",
    "'max_depth': [10,220, None],\n",
    "'min_samples_leaf': [2,12],\n",
    "'n_estimators': [280,790]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3898,   14],\n",
       "       [ 911,  981]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using a 0.6 threshold what is the false positive rate\n",
    "pointsix = []\n",
    "for each in y_pred:\n",
    "    if each > 0.7:\n",
    "        pointsix.append(1)\n",
    "    else:\n",
    "        pointsix.append(0)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pointsix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                            cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#predict the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "#calculate accuracy using a threshold of 0.6\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "accuracy_score(y_test, y_pred_round)\n",
    "#get f score, recall    and precision\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "print(f1_score(y_test, y_pred_round))\n",
    "print(recall_score(y_test, y_pred_round))\n",
    "print(precision_score(y_test, y_pred_round))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "joblib.dump(grid_search, 'grid_search_secondNight.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8339854667411962\n",
      "0.7885835095137421\n",
      "0.8849347568208779\n",
      "[[3718  194]\n",
      " [ 400 1492]]\n"
     ]
    }
   ],
   "source": [
    "#import grid_search_firstNight.pkl and run it on the test data\n",
    "#predict the test data\n",
    "grid = joblib.load('grid_search_firstNight.pkl')\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "#calculate accuracy using a threshold of 0.6\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "accuracy_score(y_test, y_pred_round)\n",
    "#get f score, recall    and precision\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "print(f1_score(y_test, y_pred_round))\n",
    "print(recall_score(y_test, y_pred_round))\n",
    "print(precision_score(y_test, y_pred_round))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "0.6975782634376846\n",
      "0.6242071881606766\n",
      "0.7904953145917001\n"
     ]
    }
   ],
   "source": [
    "#now let's preform pca and see if we can get a better model\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "#lets run a grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                            cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "#predict the test data\n",
    "y_pred = grid_search.predict(X_test_pca)\n",
    "\n",
    "#calculate accuracy using a threshold of 0.6\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "accuracy_score(y_test, y_pred_round)\n",
    "#get f score, recall    and precision\n",
    "print(f1_score(y_test, y_pred_round))\n",
    "print(recall_score(y_test, y_pred_round))\n",
    "print(precision_score(y_test, y_pred_round))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15588\n",
       "1     7628\n",
       "Name: isCanceled, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at counts of each class\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m.\u001b[39mcolumns\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#let's tale the year , month and day and make them into a single column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#let's tale the year , month and day and make them into a single column\n",
    "df['date'] = df['year'].astype(str) + df['month'].astype(str) + df['day'].astype(str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
